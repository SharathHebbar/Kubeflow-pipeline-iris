{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fe03f8",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f733e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as components\n",
    "\n",
    "from kfp import components, dsl, Client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48594d",
   "metadata": {},
   "source": [
    "# Preparing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8af8165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    from sklearn import datasets\n",
    "    import pandas as pd\n",
    "    print('Preparing Datasets')\n",
    "    iris = datasets.load_iris()\n",
    "    X = pd.DataFrame(iris.data)\n",
    "    X.columns =  ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width'] \n",
    "    y = pd.DataFrame(iris.target)\n",
    "    y.columns = ['Targets']\n",
    "    saved_folder = 'assets/'\n",
    "    x_saved_folder = 'assets/x_iris.csv'\n",
    "    y_saved_folder = 'assets/y_iris.csv'\n",
    "    X.to_csv(x_saved_folder, index=False)\n",
    "    y.to_csv(y_saved_folder, index=False)\n",
    "    \n",
    "    print(f'Data saved succesfully onto {saved_folder}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e09bd",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6ad4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    print('Train test split')\n",
    "    x_df = pd.read_csv('assets/x_iris.csv')\n",
    "    y_df = pd.read_csv('assets/y_iris.csv')\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, stratify=y_df, random_state=42)\n",
    "    y_train = np.array(y_train).reshape(-1,)\n",
    "    y_test = np.array(y_test).reshape(-1,)\n",
    "    np.save('assets/x_train.npy', x_train)\n",
    "    np.save('assets/x_test.npy', x_test)\n",
    "    np.save('assets/y_train.npy', y_train)\n",
    "    np.save('assets/y_test.npy', y_test)\n",
    "    \n",
    "    print('X and Y data are saved')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4074469",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f75c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_basic_classifier():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    print('Training Classifier')\n",
    "    \n",
    "    x_train = np.load('assets/x_train.npy', allow_pickle=True)\n",
    "    y_train = np.load('assets/y_train.npy', allow_pickle=True)\n",
    "    \n",
    "    classifier = RandomForestClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open('assets/rfc.pkl', 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "    \n",
    "    print('Random Forest Classifier is trained and the model is saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc516f",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1d3245fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    print('Predicting outcome')\n",
    "    with open('assets/rfc.pkl', 'rb') as f:\n",
    "        rfc = pickle.load(f)\n",
    "        \n",
    "    x_test = np.load('assets/x_test.npy', allow_pickle=True)\n",
    "    y_pred = rfc.predict(x_test)\n",
    "    \n",
    "    np.save('assets/y_pred.npy', y_pred)\n",
    "    \n",
    "    print('Y predicted value has been saved')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a8098",
   "metadata": {},
   "source": [
    "# Predict Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b154935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    print('Predicting Probabilities')\n",
    "    with open('assets/rfc.pkl', 'rb') as f:\n",
    "        rfc = pickle.load(f)\n",
    "        \n",
    "    x_test = np.load('assets/x_test.npy', allow_pickle=True)\n",
    "    y_pred_proba = rfc.predict_proba(x_test)\n",
    "    np.save('assets/y_pred_proba.npy', y_pred_proba)\n",
    "    print('Predicted Probabilitiy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d87242",
   "metadata": {},
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7bc5a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    \n",
    "    print('Metrics')\n",
    "    y_test = np.load('assets/y_test.npy', allow_pickle=True)\n",
    "    y_pred = np.load('assets/y_pred.npy', allow_pickle=True)\n",
    "    y_pred_proba = np.load('assets/y_pred_proba.npy', allow_pickle=True)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='micro')\n",
    "    rec = recall_score(y_test, y_pred, average='micro')\n",
    "    entropy = log_loss(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f'Model Metrics: \\nAccuracy: {round(acc, 2)}\\nPrecision: {round(prec, 2)}\\nRecall: {round(rec, 2)}\\nEntropy: {round(entropy, 2)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba9bc9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_dataset()\n",
    "# train_test_split()\n",
    "# training_basic_classifier()\n",
    "# predict_on_test_data()\n",
    "# predict_proba()\n",
    "# get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b9c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "926c78d6",
   "metadata": {},
   "source": [
    "# Kubeflow pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d97465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_prepare_data = kfp.components.create_component_from_func(\n",
    "    func=prepare_dataset,\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c3fa021",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_train_test_split = kfp.components.create_component_from_func(\n",
    "    func=train_test_split,\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b84ed096",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_training_basic_classifier = kfp.components.create_component_from_func(\n",
    "    func=training_basic_classifier,\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad05fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_predict_on_test_data = kfp.components.create_component_from_func(\n",
    "    func=predict_on_test_data,\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "349dcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_predict_prob_on_test_data = kfp.components.create_component_from_func(\n",
    "    func=predict_proba,\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5647235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_get_metrics = kfp.components.create_component_from_func(\n",
    "    func=get_metrics,\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777e3fa",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "71c409cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='IRIS Classification using Random Forest Classifier',\n",
    "    description='A Pipeline to perform classification task'\n",
    ")\n",
    "\n",
    "def iris_classifier_pipeline(data_path: str):\n",
    "    vop = dsl.VolumeOp(name='t-vol', resource_name='t-vol', size='1Gi', modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "    prepare_data = create_step_prepare_data().add_pvolumes({data_path: vop.volume})\n",
    "    train_test_split = create_step_train_test_split().add_pvolumes({data_path: vop.volume}).after(prepare_data)\n",
    "    classifier = create_step_training_basic_classifier().add_pvolumes({data_path: vop.volume}).after(train_test_split)\n",
    "    log_predicted_class = create_step_predict_on_test_data().add_pvolumes({data_path: vop.volume}).after(classifier)\n",
    "    log_predicted_probabilities = create_step_predict_prob_on_test_data().add_pvolumes({data_path: vop.volume}).after(log_predicted_class)\n",
    "    log_metrics = create_step_get_metrics().add_pvolumes({data_path: vop.volumes}).after(log_predicted_probabilities)\n",
    "    \n",
    "    prepare_data.execution_options.caching_strategy.max_cache_staleness = 'P0D'\n",
    "    train_test_split.execution_options.caching_strategy.max_cache_staleness = 'P0D'\n",
    "    classifier.execution_options.caching_strategy.max_cache_staleness = 'P0D'\n",
    "    log_predicted_class.execution_options.caching_strategy.max_cache_staleness = 'P0D'\n",
    "    log_predicted_probabilities.execution_options.caching_strategy.max_cache_staleness = 'P0D'\n",
    "    log_metrics.execution_options.caching_strategy.max_cache_staleness = 'P0D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77b37fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=iris_classifier_pipeline,\n",
    "    package_path='IRIS_classifier_pipeline.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394681d7",
   "metadata": {},
   "source": [
    "# Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d81034fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e10e1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/d1ff893e-c145-4d26-86be-2f4cc6a2e09f\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/0de8c05b-8221-416f-869e-657fb97c5aa1\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA = '/assets'\n",
    "\n",
    "import datetime\n",
    "print(datetime.datetime.now().date())\n",
    "\n",
    "pipeline_func = iris_classifier_pipeline\n",
    "experiment_name = 'iris_classifier_exp' + \"_\" + str(datetime.datetime.now().date())\n",
    "run_name = pipeline_func.__name__+' run'\n",
    "namespace = \"kubeflow\"\n",
    "\n",
    "arguments = {\"data_path\": DATA}\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func, '{}.zip'.format(experiment_name))\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    pipeline_func,\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    arguments=arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26255493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc94b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85a1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
